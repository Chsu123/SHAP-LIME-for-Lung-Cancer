{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pL59obbM5DKI"
      },
      "outputs": [],
      "source": [
        "# installing other requirements\n",
        "!pip install loguru\n",
        "!pip install LIME\n",
        "!pip install shap\n",
        "import warnings\n",
        "# Ignore all warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from loguru import logger\n",
        "from sklearn.feature_selection import RFE\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "import shap\n",
        "from shap import Explainer, TreeExplainer, Explanation\n",
        "from shap.plots import waterfall\n",
        "from shap.maskers import Independent"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "klru9GtIWmqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/cancer patient data sets.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "9_PuCcbj5lPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropping the prediction variable i.e. level and two feaure variables which is patient id and index."
      ],
      "metadata": {
        "id": "yO__sZJuXZUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "level = df['Level']\n",
        "df = df.drop(['index', 'Patient Id', 'Level'], axis=1)\n",
        "\n",
        "# Getting total number of classes\n",
        "classes = level.unique()"
      ],
      "metadata": {
        "id": "Gps3mQfn52Jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling the dataset"
      ],
      "metadata": {
        "id": "BSXULjtFXpMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardizing the dataframe\n",
        "scaler = StandardScaler()\n",
        "# Standardize the dataframe\n",
        "df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
        "\n",
        "#splitting\n",
        "X_train_temp, X_test, y_train_temp, y_test = train_test_split(df, level, test_size=0.2, random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_temp, y_train_temp, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train_shap = X_train\n",
        "X_valid_shap = X_valid\n",
        "X_test_shap = X_test\n",
        "\n",
        "y_train_shap = y_train\n",
        "y_valid_shap = y_valid\n",
        "y_test_shap = y_test\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_valid = np.array(X_valid)\n",
        "X_test = np.array(X_test)\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_valid = np.array(y_valid)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "y_encoded_train = label_encoder.fit_transform(y_train)\n",
        "y_one_hot_train = onehot_encoder.fit_transform(y_encoded_train.reshape(-1, 1))\n",
        "\n",
        "y_encoded_valid = label_encoder.fit_transform(y_valid)\n",
        "y_one_hot_valid = onehot_encoder.fit_transform(y_encoded_valid.reshape(-1, 1))\n",
        "\n",
        "y_encoded_test = label_encoder.fit_transform(y_test)\n",
        "y_one_hot_test = onehot_encoder.fit_transform(y_encoded_test.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "mIOAFUZykhK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest with Grid Search"
      ],
      "metadata": {
        "id": "_RkZA-GJVlpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# implementing grid search\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [5, 10, 50, 100, 150],\n",
        "    'max_depth': [1, 5, 10],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Initialize the Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier()\n",
        "\n",
        "# Create a GridSearchCV instance\n",
        "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5)\n",
        "\n",
        "# Perform grid search on the training data\n",
        "grid_search.fit(X_train, y_one_hot_train)\n",
        "\n",
        "# Print the best hyperparameters and the best score\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Best Score:\", grid_search.best_score_)"
      ],
      "metadata": {
        "id": "XhO5rXLnQp5p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad61211e-b52f-4dc0-fa94-d1e3d3aad679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 5}\n",
            "Best Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_classifier = RandomForestClassifier(max_depth=5, min_samples_leaf= 1, min_samples_split= 2, n_estimators= 50)\n",
        "\n",
        "# Train the classifier\n",
        "rf_classifier.fit(X_train, y_one_hot_train)"
      ],
      "metadata": {
        "id": "GHDaHXJoDn4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics calculation on validation dataset"
      ],
      "metadata": {
        "id": "4EdybQyYX99o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate the model\n",
        "valid_predictions = rf_classifier.predict(X_valid)\n",
        "valid_predictions = np.argmax(valid_predictions, axis=1)\n",
        "valid_predictions = label_encoder.inverse_transform(valid_predictions)\n"
      ],
      "metadata": {
        "id": "xwiclBi9v2pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate the model\n",
        "valid_predictions = rf_classifier.predict(X_valid)\n",
        "valid_predictions = np.argmax(valid_predictions, axis=1)\n",
        "valid_predictions = label_encoder.inverse_transform(valid_predictions)\n",
        "\n",
        "truth_valid = np.argmax(y_one_hot_valid, axis=1)\n",
        "truth_valid = label_encoder.inverse_transform(truth_valid)\n",
        "\n",
        "valid_accuracy = accuracy_score(truth_valid, valid_predictions)\n",
        "print(\"Validation Accuracy:\", valid_accuracy)\n",
        "valid_precision = precision_score(truth_valid, valid_predictions, average='micro')\n",
        "print(\"Validation Precision:\", valid_precision)\n",
        "valid_recall = recall_score(truth_valid, valid_predictions, average='micro')\n",
        "print(\"Validation Recall:\", valid_recall)\n",
        "valid_f1 = f1_score(truth_valid, valid_predictions, average='micro')\n",
        "print(\"Validation Recall:\", valid_f1)\n",
        "report = classification_report(truth_valid, valid_predictions, target_names=classes)\n",
        "label_map=label_encoder.inverse_transform([0,1,2])\n",
        "print(f\"Classification Report: \\n{report}\")\n",
        "cm = confusion_matrix(truth_valid, valid_predictions)\n",
        "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues',xticklabels=label_map,yticklabels=label_map)\n",
        "plt.title(\"Heatmap for Lung Cancer Prediction for Validation Dataset\")\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T2JlFIAeFtka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics calculation on test dataset"
      ],
      "metadata": {
        "id": "wqjR9_OfYGVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "test_predictions = rf_classifier.predict(X_test)\n",
        "test_predictions = np.argmax(test_predictions, axis=1)\n",
        "test_predictions = label_encoder.inverse_transform(test_predictions)\n",
        "\n",
        "truth_test = np.argmax(y_one_hot_test, axis=1)\n",
        "truth_test = label_encoder.inverse_transform(truth_test)\n",
        "\n",
        "test_accuracy = accuracy_score(truth_test, test_predictions)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "test_precision = precision_score(truth_test, test_predictions, average='micro')\n",
        "print(\"Test Precision:\", test_precision)\n",
        "test_recall = recall_score(truth_test, test_predictions, average='micro')\n",
        "print(\"Test Recall:\", test_recall)\n",
        "test_f1 = f1_score(truth_test, test_predictions, average='micro')\n",
        "print(\"Test Recall:\", test_f1)\n",
        "report = classification_report(truth_test, test_predictions, target_names=classes)\n",
        "\n",
        "print(f\"Classification Report: \\n{report}\")\n",
        "cm = confusion_matrix(truth_test, test_predictions)\n",
        "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues',xticklabels=label_map,yticklabels=label_map)\n",
        "plt.title(\"Heatmap for Lung Cancer Prediction for Testing Dataset\")\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RgkavMRVFvOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = X_train.shape[0]\n",
        "print(\"Training dataset size:\", train_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGMY-Ph0_pJz",
        "outputId": "16e5bcfc-ac45-4c18-d411-09dbd4d18c92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset size: 640\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RFE for Random Forest"
      ],
      "metadata": {
        "id": "4xJh7p4Touhu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recursive Feature Elimination (RFE) is a feature selection technique that can be used with the Random Forest algorithm. RFE aims to select the most relevant features by recursively eliminating less important features from the dataset. It works by training a model, such as a Random Forest, and ranking the features based on their importance or contribution to the model's performance. The least important features are then removed, and the process is repeated until the desired number of features is reached."
      ],
      "metadata": {
        "id": "XfparTmwYmH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RFE for Random Forest\n",
        "\n",
        "rfe = RFE(estimator=rf_classifier, n_features_to_select=len(df.columns))  # Select 2 features\n",
        "\n",
        "# Fit the RFE object to the data\n",
        "rfe.fit(X_train, y_one_hot_train)\n",
        "\n",
        "# Get the selected feature indices and their rankings\n",
        "selected_feature_indices = rfe.get_support(indices=True)\n",
        "feature_rankings = rfe.ranking_\n",
        "\n",
        "# Print the selected feature indices and their rankings\n",
        "print(\"Selected feature indices:\", selected_feature_indices)\n",
        "print(\"Feature rankings:\", feature_rankings)\n"
      ],
      "metadata": {
        "id": "rONL1-6tZT5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get feature importances\n",
        "importances = rf_classifier.feature_importances_\n",
        "\n",
        "# Calculate the standard deviation of feature importances across trees\n",
        "std = np.std([tree.feature_importances_ for tree in rf_classifier.estimators_], axis=0)\n",
        "\n",
        "# Create a Series with feature importances and corresponding column names\n",
        "forest_importances = pd.Series(importances, index=df.columns)\n",
        "\n",
        "# Create a figure and axis for plotting\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Plot the feature importances as a bar chart with error bars using the standard deviation\n",
        "forest_importances.plot.bar(yerr=std, ax=ax)\n",
        "\n",
        "# Set the title and y-axis label\n",
        "ax.set_title(\"Feature importances\")\n",
        "ax.set_ylabel(\"Mean decrease in impurity\")\n",
        "\n",
        "# Adjust the layout of the figure\n",
        "fig.tight_layout()"
      ],
      "metadata": {
        "id": "oNxNEJf5TjIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LIME"
      ],
      "metadata": {
        "id": "-hwo511GWhJV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "LIME (Local Interpretable Model-Agnostic Explanations) is a popular technique for explaining the predictions of machine learning models. It provides interpretable explanations for individual predictions by approximating the behavior of the underlying model in the local neighborhood of the instance being explained."
      ],
      "metadata": {
        "id": "Wtct_jcpYuZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Lime Explainer object\n",
        "explainer = lime.lime_tabular.LimeTabularExplainer(training_data=X_train,\n",
        "                                                   feature_names=list(df.columns),\n",
        "                                                   class_names=classes)"
      ],
      "metadata": {
        "id": "hIqKVSgNF7Xq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**N instances on Test Data**"
      ],
      "metadata": {
        "id": "GKNeIt2KHZv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the predicted classes and probabilities for all instances in the test set\n",
        "pred_probs = rf_classifier.predict(X_test)\n",
        "pred_classes = np.argmax(pred_probs, axis=1)\n",
        "pred_classes = label_encoder.inverse_transform(pred_classes)\n",
        "\n",
        "# Define the number of samples\n",
        "samples_class = 11\n",
        "print(\"first \", samples_class,\" samples labels\", y_test[:samples_class])\n",
        "\n",
        "# Create a list to store sample instances for each class\n",
        "sample_instances_list = []\n",
        "\n",
        "for s in range(samples_class):\n",
        "    # Get the sample and append them to the list\n",
        "    sample_instances_list.append([X_test[s]])\n",
        "\n",
        "# Loop through the sample instances and generate an explanation for each one\n",
        "for sample_instances in sample_instances_list:\n",
        "    for i, sample_instance in enumerate(sample_instances):\n",
        "        sample_instance = sample_instance.reshape(1, -1)\n",
        "        # Get the predicted class and probability of the sample instance\n",
        "        pred_prob = rf_classifier.predict(sample_instance)[0]\n",
        "        pred_class = np.argmax(pred_prob)\n",
        "        class_value = label_encoder.inverse_transform((pred_class.reshape(-1, 1)))\n",
        "        prob = pred_prob[pred_class]\n",
        "\n",
        "        # Use the Lime explainer to generate an explanation for the sample instance\n",
        "        exp = explainer.explain_instance(sample_instance.reshape(X_valid.shape[1],),\n",
        "                                         rf_classifier.predict,\n",
        "                                         num_features=X_valid.shape[1])\n",
        "\n",
        "        # Create a DataFrame for the explanation\n",
        "        exp_df = pd.DataFrame(exp.as_list(), columns=['Feature', 'Weight'])\n",
        "\n",
        "        # Add a column for the absolute value of the weights\n",
        "        exp_df['Absolute Weight'] = exp_df['Weight'].abs()\n",
        "\n",
        "        # Sort the DataFrame by the absolute value of the weights\n",
        "        exp_df = exp_df.sort_values('Absolute Weight', ascending=False)\n",
        "\n",
        "        # Reset the index and display the DataFrame\n",
        "        exp_df = exp_df.reset_index(drop=True)\n",
        "\n",
        "        print('Sample Instance', i+1, 'Class:', class_value)\n",
        "        print('Predicted Probability:', prob)\n",
        "\n",
        "        # Set the display options to show all rows and columns\n",
        "        pd.set_option('display.max_rows', None)\n",
        "        pd.set_option('display.max_columns', None)\n",
        "\n",
        "        print('LIME Explanation:')\n",
        "        display(exp_df)\n",
        "        print('-----------------------\\n')\n",
        "\n",
        "\n",
        "        # Plotting\n",
        "        exp_df=exp_df.iloc[:8]\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.bar(exp_df['Feature'], exp_df['Weight'])\n",
        "        plt.xlabel('Feature')\n",
        "        plt.ylabel('Weight')\n",
        "        plt.title('Feature Weights')\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zp6eHD8AHbvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Aggregated LIME results for all 3 classes on Test Data**"
      ],
      "metadata": {
        "id": "WVtXEsSSV39U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the predicted classes and probabilities for all instances in the test set\n",
        "pred_probs = rf_classifier.predict(X_test)\n",
        "pred_classes = np.argmax(pred_probs, axis=1)\n",
        "pred_classes = label_encoder.inverse_transform(pred_classes)\n",
        "\n",
        "samples_class = X_test.shape[0]  # Set the number of samples per class to the size of the test set\n",
        "sample_instances_list = []  # Create a list to store sample instances for each class\n",
        "\n",
        "# Loop through each class and choose a sample instance from that class\n",
        "for c in [\"High\", \"Low\", \"Medium\"]:\n",
        "    # Find the indices of the instances in the test set that belong to this class\n",
        "    ids = np.where(pred_classes == c)[0][:samples_class]\n",
        "    sample_instances_list.append(X_test[ids, :])  # Get the sample instances per class and append them to the list\n",
        "\n",
        "for sample_instances in sample_instances_list:\n",
        "    # Loop through the sample instances and generate an explanation for each one\n",
        "    class_results = []\n",
        "    all_values = []\n",
        "    for i, sample_instance in enumerate(sample_instances):\n",
        "        sample_instance = sample_instance.reshape(1, -1)\n",
        "        # Get the predicted class and probability of the sample instance\n",
        "        pred_prob = rf_classifier.predict(sample_instance)[0]\n",
        "        pred_class = np.argmax(pred_prob)\n",
        "        class_value = label_encoder.inverse_transform((pred_class.reshape(-1, 1)))\n",
        "        prob = pred_prob[pred_class]\n",
        "\n",
        "        # Use the Lime explainer to generate an explanation for the sample instance\n",
        "        exp = explainer.explain_instance(sample_instance.reshape(X_test.shape[1],),\n",
        "                                         rf_classifier.predict,\n",
        "                                         num_features=X_test.shape[1])\n",
        "        cols = np.array(exp.as_list())[:, 0]\n",
        "\n",
        "        if class_results == []:\n",
        "            class_results = list((np.array(np.array(exp.as_list())[:, 1])))\n",
        "        else:\n",
        "            class_results = np.c_[class_results, list((np.array(np.array(exp.as_list())[:, 1])))]\n",
        "\n",
        "        all_values.append(list((np.array(np.array(exp.as_list())[:, 1]))))\n",
        "\n",
        "    all_values = (np.array(all_values, dtype=np.float32))\n",
        "\n",
        "    # Compute the correlation matrix\n",
        "    total_features = 8\n",
        "    corr = np.corrcoef(all_values[:, :total_features], rowvar=False)\n",
        "\n",
        "    # Plot the heatmap\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(corr, annot=True, cmap='coolwarm', yticklabels=cols[:total_features],\n",
        "                xticklabels=cols[:total_features])\n",
        "    plt.show()\n",
        "\n",
        "    if class_results != []:\n",
        "        values = np.mean(np.array(class_results, dtype=np.float32), axis=1)\n",
        "        exp_mean = np.c_[cols, values]\n",
        "        exp_df = pd.DataFrame(exp_mean, columns=['Feature', 'Weight'])\n",
        "        exp_df = exp_df.astype({'Weight': 'float32'})\n",
        "        exp_df['Absolute Weight'] = exp_df['Weight'].abs()\n",
        "        exp_df = exp_df.sort_values('Absolute Weight', ascending=False)\n",
        "        exp_df = exp_df.reset_index(drop=True)\n",
        "\n",
        "        print('Sample Instances', i + 1, 'Class:', class_value[0])\n",
        "        print('Predicted Probability:', prob)\n",
        "        pd.set_option('display.max_rows', None)\n",
        "        pd.set_option('display.max_columns', None)\n",
        "        print('LIME Explanation:')\n",
        "        display(exp_df)\n",
        "        print('-----------------------\\n')\n",
        "        # Plotting\n",
        "        exp_df=exp_df.iloc[:8]\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.bar(exp_df['Feature'], exp_df['Weight'])\n",
        "        plt.xlabel('Feature')\n",
        "        plt.ylabel('Weight')\n",
        "        plt.title('Feature Weights')\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "YjrwDyqwGU_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SHAP"
      ],
      "metadata": {
        "id": "eq7mJ4SwW8fG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_classifier = RandomForestClassifier(max_depth=5, min_samples_leaf= 1, min_samples_split= 2, n_estimators= 50)\n",
        "# Train the classifier\n",
        "rf_classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "9hV_V7CIzx7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder.inverse_transform([0,1,2])"
      ],
      "metadata": {
        "id": "xEnKdH4epk3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = shap.Explainer(rf_classifier)\n"
      ],
      "metadata": {
        "id": "rooMAAB62ENF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SHAP on Test Data**"
      ],
      "metadata": {
        "id": "dUKthzyRRhpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shap_values = explainer(X_test_shap)\n",
        "shap_values = shap.TreeExplainer(rf_classifier).shap_values(X_test_shap)\n",
        "shap.summary_plot(shap_values, X_test_shap)\n",
        "\n"
      ],
      "metadata": {
        "id": "yHcQljUG3-PP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**N instances on Test Data**"
      ],
      "metadata": {
        "id": "vO_4GEqMWyyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of samples to display\n",
        "samples = 11\n",
        "print(\"first \", samples,\" samples labels\",  y_test[:samples])\n",
        "# Get the indices of the test dataset\n",
        "indices = list(X_test_shap.index)\n",
        "\n",
        "# Create the SHAP explainer\n",
        "explainer = TreeExplainer(rf_classifier)\n",
        "\n",
        "# Get the SHAP values for the test dataset\n",
        "sv = explainer(X_test_shap)\n",
        "\n",
        "# Create the Explanation object using the SHAP values\n",
        "exp = Explanation(\n",
        "    sv.values[:, :, 0],\n",
        "    sv.base_values[:, 1],\n",
        "    data=X_test_shap.values,\n",
        "    feature_names=X_test_shap.columns\n",
        ")\n",
        "# Iterate over the samples\n",
        "if samples > 0:\n",
        "    for i in range(samples):\n",
        "        # Create a DataFrame with the SHAP values for each feature\n",
        "        display(pd.DataFrame({\n",
        "            'row_id': indices[i],\n",
        "            'feature': X_test_shap.columns,\n",
        "            'feature_value': X_test_shap.iloc[i],\n",
        "            'base_value': exp.base_values[i],\n",
        "            'shap_values': exp.values[i]\n",
        "        }))\n",
        "\n",
        "        print('----------------------------')\n",
        "else:\n",
        "    display(pd.DataFrame({\n",
        "        'row_id': indices[samples],\n",
        "        'feature': X_test_shap.columns,\n",
        "        'feature_value': X_test_shap.iloc[samples],\n",
        "        'base_value': exp.base_values[samples],\n",
        "        'shap_values': exp.values[samples]\n",
        "    }))\n"
      ],
      "metadata": {
        "id": "t7UpAejtRD6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Aggregated SHAP on Test Data**"
      ],
      "metadata": {
        "id": "O7DhWXjfXQ9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over each class label\n",
        "# for label in [\"High\", \"Low\", \"Medium\"]:\n",
        "#     print(\"Class\", label)\n",
        "for label in [\"High\", \"Low\", \"Medium\"]:\n",
        "    print(\"Class\", label)\n",
        "\n",
        "    # Filter the test dataset based on the current label\n",
        "    df_test = X_test_shap[X_test_shap.index.isin(level[level == label].index)]\n",
        "\n",
        "    # Create the masker using the filtered dataset\n",
        "    masker = Independent(df_test, max_samples=X_test.shape[0])\n",
        "\n",
        "    # Create the SHAP explainer using the random forest classifier and the masker\n",
        "    explainer = TreeExplainer(rf_classifier, data=masker)\n",
        "\n",
        "    # Get the expected base value from the explainer\n",
        "    bv = explainer.expected_value[1]\n",
        "\n",
        "    # Get the SHAP values for the filtered dataset\n",
        "    sv = explainer(df_test, check_additivity=False)\n",
        "\n",
        "    # Create a DataFrame with the SHAP values for each feature\n",
        "    df = pd.DataFrame({\n",
        "        'row_id': df_test.index.values.repeat(df_test.shape[1]),\n",
        "        'feature': df_test.columns.to_list() * df_test.shape[0],\n",
        "        'feature_value': df_test.values.flatten(),\n",
        "        'base_value': bv,\n",
        "        'shap_values': sv.values[:, :, 1].flatten()\n",
        "    })\n",
        "\n",
        "    # Group the DataFrame by feature and calculate the mean values\n",
        "    df_mean = df.groupby('feature').mean().drop([\"row_id\"], axis=1).T\n",
        "\n",
        "    # Display the mean SHAP values for each feature\n",
        "    display(df_mean)\n",
        "\n",
        "    # Select the top features based on absolute mean SHAP values\n",
        "    total_features = 8\n",
        "    indices = np.argsort(-np.abs(df_mean.iloc[-1]))[:total_features].values\n",
        "\n",
        "    # Get the SHAP values for all instances and selected features\n",
        "    all_values = []\n",
        "    for id_ in np.unique(df['row_id']):\n",
        "        all_values.append(np.array(df[df['row_id'] == id_].T)[-1, :])\n",
        "    all_values = np.array(all_values, dtype=np.float32)[:, indices]\n",
        "\n",
        "    # Calculate the correlation matrix\n",
        "    corr = np.corrcoef(all_values, rowvar=False)\n",
        "    # Plot the heatmap of the correlation matrix\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(corr, annot=True, cmap='coolwarm', yticklabels=df_mean.columns[indices], xticklabels=df_mean.columns[indices])\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "X5anuLlP5lop"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}